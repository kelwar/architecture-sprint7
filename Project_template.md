# Задание 1. Исследование моделей и инфраструктуры

Сравнение LLM-моделей:

| Критерий                           | Perplexity R1-1776                                                   | GPT-4                                                         | YandexGPT-5               |
|------------------------------------|----------------------------------------------------------------------|---------------------------------------------------------------|---------------------------|
| Качество ответов (MMLU)            | 90.5                                                                 | 86                                                            | 63                        |
| Скорость работы                    | 49,3 токена/с                                                        | 110 токенов/с                                                 | 40 токенов/с              |
| Стоимость владения и использования | Бесплатно, стартовые затраты на оборудование                         | $0.03 за 1000 входных токенов, %0.06 за 1000 выходных токенов | 400 руб/мес.              |
| Удобство и простота развертывания  | Модель доступна на Hugging Face Hub, также возможна работа через API | Работа через API в облаке                                     | Работа через API в облаке |

Сравнение моделей эмбеддингов:

| Критерий                           | all‑MiniLM‑L6‑v2                                                                               | text-embedding-3-small                                | 
|------------------------------------|------------------------------------------------------------------------------------------------|-------------------------------------------------------|
| Скорость создания индекса          | 5–10 мс                                                                                        | 168,3 мс                                              |
| Качество поиска                    | Близко ко многим большим моделям на публичных бенчмарках, если задача — поиск похожих текстов. | Высокое                                               |
| Стоимость владения и использования | Бесплатно, вложения только в инфраструктуру                                                    | $0.02 за 1 млн токенов, без вложений в инфраструктуру |

Сравнение векторных баз ChromaDB и FAISS:

| Критерий                                 | ChromaDB                                                                                                                                                                                                                                | FAISS                                                                                                               |
|------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|
| Скорость поиска и индексации             | Поиск с малой задержкой, HNSW индексация                                                                                                                                                                                                | Очень быстрый поиск, различные варианты индексации, без поддержки индексации в реальном времени                     |
| Сложность внедрения и поддержки          | Внедрение: на своём оборудовании (любом), либо в облаке (Chroma Cloud)<br/>Масштабируется горизонтально до средних и больших наборов данных. Не подходит для очень больших наборов данных                                               | Внедрение: на своём оборудовании. Масштабирование только вертикальное, задействует все имеющиеся ядра CPU и все GPU |
| Удобство в работе                        | Имеет мощные SDK для Python и JS. Поддерживает богатый API функционал                                                                                                                                                                   | C++ библиотека с привязками к Python. Нет встроенных API                                                            |
| Стоимость владения (учёт инфраструктуры) | Бесплатная на своём оборудовании.<br/>Chroma Cloud предполагает платежи:<br/>Запись: $2.5 за 1ГиБ<br/>Чтение: $0.0075 за 1ТиБ отсканированный и $0.09 за 1ГиБ возвращенный<br/>Форк: $0.03 за 1 запрос<br/>Хранение: $0.33 за 1ГиБ/мес. | Бесплатная, на своём оборудовании                                                                                   |

Конфигурация сервера:
CPU: многоядерный процессор с поддержкой AVX2/FMA инструкций от 3 ГГц
RAM: 32 ГБ
GPU: NVIDIA 16 ГБ памяти

Решение:
Для выполнения задачи предлагается выбрать open-source LLM-модель Preplexity AI R1-1776, как модель с довольно качественными ответами по сравнению с другими LLM-моделями (90% правильных ответов, довольно неплохой результат).
Заточенность модели на поиск данных также является преимуществом. 
Кроме того, доступность весов на Hugging Face Hub позволяет работать с моделью более гибко и донастраивать её при необходимости, в отличие от проприетарных (облачных) LLM-моделей.
Плюс к вышесказанному, предполагается обработка большого количества запросов, формирование большого количества токенов, что в случае использования GPT-4 существенно увеличило бы стоимость решения.
Выделение средств на новый сервер on-premise окупится со временем.
В качестве модели эмбеддингов предлагается использовать рассмотренную выше all‑MiniLM‑L6‑v2, как модель с достаточно быстрым временем ответа и достойным уровнем качества поиска.
Между Chroma DB и FAISS предлагается выбрать FAISS за её очень быстрый поиск, что положительным образом скажется на пользовательском опыте и снизит временные затраты на поиск материалов. 

# Задание 2. Подготовка базы знаний

В качестве базы знаний использована вселенная мира книг "Песнь льдя и пламени" Джорджа Мартина. 
В качестве материалов - статьи из "плиопедии" (энциклопедия мира) сайта 7kingdoms.ru. 
Т.к. локаций, персонажей и переплетений очень много, статьи упрощены, иначе 30+ дали бы огромнейший файл terms_map.json с очень большим количеством имён.
Имена собственные заменены с помощью поиска по содержимому файлов и автозамены средствами IntelliJ Idea на основании составленного вручную terms_map.json.

# Задание 3. Создание векторного индекса базы знаний

1. Эмбеддинг-модель:
- all‑MiniLM‑L6‑v2, 
- https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
- размер эмбеддингов 384

2. 

# Задание 4. Реализация RAG-бота с техниками промптинга

# Задание 5. Запуск и демонстрация работы бота